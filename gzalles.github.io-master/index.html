<!-- <!DOCTYPE html> -->
<html>

<head>
	<link href='https://fonts.googleapis.com/css?family=Raleway' rel='stylesheet' type='text/css'>
	<link href='styles/style.css' rel='stylesheet' type='text/css'>
	<meta charset='utf-8'>
	<title>Web Audio Class NYU</title>

	<head>

		<body>
			<img src="images/sound-2.jpg" alt="Digitized sound">
			<!--test sound-->
			<button type="button" onclick="osc()">Test sound</button>
			<!--web site title-->
			<h1>Immersive Web Audio Project</h1>
			<!--each header links to subsection of project-->
			<h2><a href="/html/binaural.html">Phase I: Implement Binaural</a></h2>
			<ul>
				<li> Explore the Web Audio API and write code which allows user to get stereo sound from soundcard to web page. </li>
				<li> Test using the 3Dio from NYU or any of the other binaural microphones. </li>
				<li> Incorporate a volume control for the audio (and maybe a panner). </li>
				<li> Listen to the results on headphones to evaluate for quality plus let user know headphones are necessary.</li>
			</ul>
			<h2><a href="/html/ambisonic.html">Phase II: Incorporate Ambisonics Bed</a></h2>
			<ul>
				<li> Use a 4 channel soundcard and a tetra mic to get first order ambisonic audio into the site.</li>
				<li> The 4 channels should be decoded in the backend to B-format (W, X, Y, Z).</li>
				<li> The B-format is then decoded with omnitone into 8 speakers.</li>
				<li> The user should be able to rotate and control the overall volume of the sound-field.</li>
			</ul>
			<h2>Phase III: OBA</h2>
			<ul>
				<li> Allow spot mics to work as audio objects.</li>
				<li> Create function that let's user pick channels from soundcard as audio objects.</li>
				<li> The user defines where the signal will be in 3D space (coordinate positioning UI).</li>
				<li> Every object will come with an associated volume control.</li>
			</ul>
			<h2> Phase IV: Future Development </h2>
			<ul>
				<li> Make it stream live</li>
				<li> Mixing on user side during livestream</li>
				<li> 360 live video streaming</li>
			</ul>

			<h2> More info </h2>

			<p> By the end of the semester I intend to have phase I done. This is close to what the immersive audio group has already accomplished which is binaural streaming with 360 video. I will use the binaural ears myself and a GoPro to try to stream a concert
				(perhaps the SWiTch concert [society for women in technology]). If the streaming is not accomplished on time I will just record them with the tetra mic and attempt to use this audio on the website. The stream will not be live but at least I will get
				a sense of what it is like to work with Omnitone. I am looking at different ways of doing the live stream I am currently leaning towards NodeJS due to it's flexibility. </p>

			<h2> Requirements and considerations: </h2>
			<ul>
				<li> Streaming Protocol: HTTP </li>
				<li> Adaptive Streaming?</li>
				<li> CODEC? ogg vorbis, mp3, other... </li>
				<li> Supported Browsers? Chrome, Firefox, Safari... </li>
			</ul>

			<h2>Some Useful Links</h2>
			<ul>
				<!--unordered list-->
				<li><a href="https://github.com/GoogleChrome/omnitone/">Omnitone</a></li>
				<li><a href="https://github.com/gzalles/gzalles.github.io"> Github</a> </li>
				<li><a href="https://nodejs.org/en/"> NodeJS</a></li>
				<li><a href="https://www.npmjs.com/"> NPM</a></li>
			</ul>

			<script src='scripts/osc.js'>
			</script>
			<script src='scripts/main.js'></script>
		</body>

</html>
